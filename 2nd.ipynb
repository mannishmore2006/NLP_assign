{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b5ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import sklearn tools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Import Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Import tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download tokenizer model\n",
    "nltk.download('punkt')\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Download missing tokenizer tables\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d336bf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural language processing is fun',\n",
       " 'I love learning natural language processing',\n",
       " 'Word embeddings are useful in NLP',\n",
       " 'Bag of words and TF IDF are basic NLP techniques']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample dataset (documents)\n",
    "documents = [\n",
    "    \"Natural language processing is fun\",\n",
    "    \"I love learning natural language processing\",\n",
    "    \"Word embeddings are useful in NLP\",\n",
    "    \"Bag of words and TF IDF are basic NLP techniques\"\n",
    "]\n",
    "\n",
    "# Display documents\n",
    "documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e67b9c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>bag</th>\n",
       "      <th>basic</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>fun</th>\n",
       "      <th>idf</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>natural</th>\n",
       "      <th>nlp</th>\n",
       "      <th>of</th>\n",
       "      <th>processing</th>\n",
       "      <th>techniques</th>\n",
       "      <th>tf</th>\n",
       "      <th>useful</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  are  bag  basic  embeddings  fun  idf  in  is  language  ...  love  \\\n",
       "0    0    0    0      0           0    1    0   0   1         1  ...     0   \n",
       "1    0    0    0      0           0    0    0   0   0         1  ...     1   \n",
       "2    0    1    0      0           1    0    0   1   0         0  ...     0   \n",
       "3    1    1    1      1           0    0    1   0   0         0  ...     0   \n",
       "\n",
       "   natural  nlp  of  processing  techniques  tf  useful  word  words  \n",
       "0        1    0   0           1           0   0       0     0      0  \n",
       "1        1    0   0           1           0   0       0     0      0  \n",
       "2        0    1   0           0           0   0       1     1      0  \n",
       "3        0    1   1           0           1   1       0     0      1  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create CountVectorizer object\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "bow_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to DataFrame for readability\n",
    "bow_df = pd.DataFrame(\n",
    "    bow_matrix.toarray(),\n",
    "    columns=count_vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "bow_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a441f645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>bag</th>\n",
       "      <th>basic</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>fun</th>\n",
       "      <th>idf</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>natural</th>\n",
       "      <th>nlp</th>\n",
       "      <th>of</th>\n",
       "      <th>processing</th>\n",
       "      <th>techniques</th>\n",
       "      <th>tf</th>\n",
       "      <th>useful</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   and       are  bag  basic  embeddings  fun  idf        in   is  language  \\\n",
       "0  0.0  0.000000  0.0    0.0    0.000000  0.2  0.0  0.000000  0.2       0.2   \n",
       "1  0.0  0.000000  0.0    0.0    0.000000  0.0  0.0  0.000000  0.0       0.2   \n",
       "2  0.0  0.166667  0.0    0.0    0.166667  0.0  0.0  0.166667  0.0       0.0   \n",
       "3  0.1  0.100000  0.1    0.1    0.000000  0.0  0.1  0.000000  0.0       0.0   \n",
       "\n",
       "   ...  love  natural       nlp   of  processing  techniques   tf    useful  \\\n",
       "0  ...   0.0      0.2  0.000000  0.0         0.2         0.0  0.0  0.000000   \n",
       "1  ...   0.2      0.2  0.000000  0.0         0.2         0.0  0.0  0.000000   \n",
       "2  ...   0.0      0.0  0.166667  0.0         0.0         0.0  0.0  0.166667   \n",
       "3  ...   0.0      0.0  0.100000  0.1         0.0         0.1  0.1  0.000000   \n",
       "\n",
       "       word  words  \n",
       "0  0.000000    0.0  \n",
       "1  0.000000    0.0  \n",
       "2  0.166667    0.0  \n",
       "3  0.000000    0.1  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize BoW by dividing each row by total word count in that document\n",
    "normalized_bow = bow_df.div(bow_df.sum(axis=1), axis=0)\n",
    "\n",
    "normalized_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d480f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>are</th>\n",
       "      <th>bag</th>\n",
       "      <th>basic</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>fun</th>\n",
       "      <th>idf</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>natural</th>\n",
       "      <th>nlp</th>\n",
       "      <th>of</th>\n",
       "      <th>processing</th>\n",
       "      <th>techniques</th>\n",
       "      <th>tf</th>\n",
       "      <th>useful</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508672</td>\n",
       "      <td>0.401043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508672</td>\n",
       "      <td>0.401043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436719</td>\n",
       "      <td>0.436719</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328919</td>\n",
       "      <td>0.259324</td>\n",
       "      <td>0.328919</td>\n",
       "      <td>0.328919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259324</td>\n",
       "      <td>0.328919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328919</td>\n",
       "      <td>0.328919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        and       are       bag     basic  embeddings       fun       idf  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000    0.000000  0.508672  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.344315  0.000000  0.000000    0.436719  0.000000  0.000000   \n",
       "3  0.328919  0.259324  0.328919  0.328919    0.000000  0.000000  0.328919   \n",
       "\n",
       "         in        is  language  ...      love   natural       nlp        of  \\\n",
       "0  0.000000  0.508672  0.401043  ...  0.000000  0.401043  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.401043  ...  0.508672  0.401043  0.000000  0.000000   \n",
       "2  0.436719  0.000000  0.000000  ...  0.000000  0.000000  0.344315  0.000000   \n",
       "3  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.259324  0.328919   \n",
       "\n",
       "   processing  techniques        tf    useful      word     words  \n",
       "0    0.401043    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1    0.401043    0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2    0.000000    0.000000  0.000000  0.436719  0.436719  0.000000  \n",
       "3    0.000000    0.328919  0.328919  0.000000  0.000000  0.328919  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform documents\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "tfidf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05508dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['natural', 'language', 'processing', 'is', 'fun'],\n",
       " ['i', 'love', 'learning', 'natural', 'language', 'processing'],\n",
       " ['word', 'embeddings', 'are', 'useful', 'in', 'nlp'],\n",
       " ['bag',\n",
       "  'of',\n",
       "  'words',\n",
       "  'and',\n",
       "  'tf',\n",
       "  'idf',\n",
       "  'are',\n",
       "  'basic',\n",
       "  'nlp',\n",
       "  'techniques']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize each document into words\n",
    "tokenized_docs = [word_tokenize(doc.lower()) for doc in documents]\n",
    "\n",
    "tokenized_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d412fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(\n",
    "    sentences=tokenized_docs,\n",
    "    vector_size=50,   # Size of word embedding\n",
    "    window=5,         # Context window size\n",
    "    min_count=1,      # Include all words\n",
    "    workers=4         # Number of CPU threads\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c097fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01723938,  0.00733148,  0.01037977,  0.01148388,  0.01493384,\n",
       "       -0.01233535,  0.00221123,  0.01209456, -0.0056801 , -0.01234705,\n",
       "       -0.00082045, -0.0167379 , -0.01120002,  0.01420908,  0.00670508,\n",
       "        0.01445134,  0.01360049,  0.01506148, -0.00757831, -0.00112361,\n",
       "        0.00469675, -0.00903806,  0.01677746, -0.01971633,  0.01352928,\n",
       "        0.00582883, -0.00986566,  0.00879638, -0.00347915,  0.01342277,\n",
       "        0.0199297 , -0.00872489, -0.00119868, -0.01139127,  0.00770164,\n",
       "        0.00557325,  0.01378215,  0.01220219,  0.01907699,  0.01854683,\n",
       "        0.01579614, -0.01397901, -0.01831173, -0.00071151, -0.00619968,\n",
       "        0.01578863,  0.01187715, -0.00309133,  0.00302193,  0.00358008],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get embedding vector for a word\n",
    "word2vec_model.wv['language']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10d6a78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 0.1960817128419876),\n",
       " ('natural', 0.16563552618026733),\n",
       " ('i', 0.15517635643482208),\n",
       " ('embeddings', 0.14385901391506195),\n",
       " ('tf', 0.13940520584583282),\n",
       " ('are', 0.12670199573040009),\n",
       " ('fun', 0.1211962178349495),\n",
       " ('basic', 0.10519503057003021),\n",
       " ('learning', 0.08872983604669571),\n",
       " ('of', 0.03227848559617996)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find words similar to 'language'\n",
    "word2vec_model.wv.most_similar('language')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190712b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
